# S3

- Global Storage Platform
- Regional based / resilient
- Public service
	- może być wystawiony na zewnątrz i może być dostępny za pomocą endpointów
- **EXAM** S3 jest **Private by default**
- Nadaje się do przechowywania dużej ilości danych do dystrybucji lub jako miejsce uploadu
- Powinno być używane jako input i output serwisów AWS

## Objects
- Pliki na S3
- **EXAM** Obiekt S3 może mieć od __zera__ bajtów do __5TB__
- `Object key` to jego adres w S3
- Obiekty posiadają:
	- Version ID
	- Metadata
	- Access Control
	- Subresources
- **EXAM** Obiekt ma główne dwie częsci - key i value

## Buckets
- Pojemniki na obiekty
	- Nieskończona ilość obiektów
	- "S3 is an __object__ store - not __file__ nor __block__"
		- nie ma systemu plików, jest płaski
		- nie można go zamontować jako voluminu
	- Wszystkie obiekty są przechowywane __na tym samym poziomie__ - nie ma folderów i podfolderów, są __klucze__
	- UI i CLI przedstawi zawartość Bucketa jako foldery i podfoldery ale w rzeczywistości ma płaską strukturę
		- `folder` w języku S3 nazywa się `prefix`
		- jak `tworzymy nowy folder foo` to tak naprawdę tworzymy obiekt o nazwie `foo/`
- Nazwy Bucketów:
	- **EXAM** Nazwa Bucketu S3 musi być globalnie unique
	- **EXAM** Nazwy Bucketów S3 muszą mieć 3-63 znaki, lowercase, bez podłóg
	- **EXAM** Nazwy Bucketów S3 muszą zaczynać się od małej litery lub cyfry
	- **EXAM** Nazwy Bucketów S3 nie mogą byc formatowane jak adresy IP
- **EXAM** Konto ma soft limit do 100 Bucketów S3 i hard limit do 1000 (via support tickets)
- Istnieją w kontekście regionu
	- Dane z Bucketu nie opuszczają regionu chyba że eksplicite to zrobimy
- Aby usunąć bucket najpierw musimy go opróźnić
	- Bukcets -> Wybrać Bucket -> Empty
	- Delete
- Bucket może mieć nałożone `Resource Policy`
	- Bucket może mieć tylko jedno Resource Policy ale może ono mieć wiele statement

## S3 Bucket Policies (Resource Policy, Security)
- Bucket S3 domyślnie tworzony jest prywany, ma do niego dostęp tylko root user konta któro go stworzyło, ale możemy go otworzyć na publiczny dostęp
- Przy tworzeniu bucketu S3 mamy opcję `Block all public access` - zaznaczenie jej __blokuje__ możliwość udostępnienia bucketu publicznie. Jak odhaczymy tę opcję to bucket nie staje się od razu publiczny ale otwiera się możliwość ustawienia go jako publicznego

### Block all public access
- Mają znaczenie tylko kiedy Anonymous Principal próbuje uzyskać dostęp do bucketu S3

## ACL Access Control List
- Pozwala na zabezpieczanie Objektów lub Bucketów
- ACL to Subresource Objektów lub Bucketów
- Legacy feature, AWS zaleca używanie IAM Policy lub Resource Policy zamiast nich
- O wiele mniej flexible niż Policy

## Static Website Hosting
- Pozwala na dostęp do S3 via HTTP
- Musimy zdefiniować:
	- `Index document`
		- Strona wejściowa naszej strony
		- Domyślna strona na której ląduje konsument
	- `Error document`
		- Dokument który jest wyświetlony w momencie wystapienia błędu
- Po włączeniu tego AWS tworzy dla bucketu Website Endpoint którego można użyć żeby uzyskać dostęp do strony
	- Ten endpoint jest dziwny i wielki, ale możemy użyć R53 żeby stworzyć customową domenę
	- Żeby R53 mógł stworzyć taką domenę to **nazwa bucketu musi być taka sama jak domena**
		- np. domena `foo.bar.org` musi mie bucket `xxx.foo.bar.org` 

Use case:
1.	Offloading
	- Trzymanie statycznych części dynamicznej strony na S3
	- Np. obrazki, statyczne elementy
2.	Out-of-band pages
	- Strony które powinny być dostępne w nieczęstych, nienormalnych sytuacjach
	- np. hostujemy strone na EC2, EC2 pada ale na S3 mamy statyczną stronę na którą możemy przekierować traffic

Włączenie:
1.	S3 -> stworzyć Bucket
2.	Properties -> na sam dół -> Static Website Hosting
	- Na razie będziemy dostawać 403 bo bucket jest niedostepny publicznie
3.	Permissions -> Stworzyć opowiedni BucketPolicy
4.	Żeby mieć elegancki adres trzeba jeszcze skonfigurować Routing w Route53

## Bucket Versioning
-   **EXAM** Bucket Versioning często jest na egzaminie
-   **EXAM** Raz włączonego Bucket Versioning nie można już wyłączyć!!
- **EXAM** Object Versionig można przestawić w `SUSpended`
- **EXAM** Suspended mozna przestawić ponownie w `Enabled`

- Każdy obiekt w S3 oprócz klucza ma też unikanle `ID`
	- `ID` jest nullem jeżeli OV jest wyłączony
- Po włączeniu OV każdy obiekt dostaje swoje ID

### Zmiany w obiekcie
- Jeżeli zmienimy coś w danym obiekcie to poprzednia wersja obiektu dalej isniteje, nie nadpisujemy jej, pojawia się nowy obiekt o tym samym kluczu ale innym ID

### Usuwanie obiektu
- Jeżeli usuwamy obiekt bez podania `Version ID` obiektu obiekt nie zostaje tak naprawdę usunięty
	- Tworzy się tylko `Delete Marker` który przykrywa ten obiekt i sprawia że wygląda jakby został usunięty
	- Jeżeli pozbędziemy sie tego `Delete Marker` to obiekt i wszystkie jego wersje są ponownie widoczne
- Jezeli usuwamy konkretną wersję obiektu (`Version Delete`) to ta wersja usuwana jest naprawdę i nie ma już do niej dostępu

### Koszty
- Każda wersja obiektu na S3 zajmuje miejsce i płacimy za to miejsce
- Nie da sie wyłączyć wersjonowania, można je jedynie zatrzymać tymczasowo
- Jedyny sposób na usunięcie wersjonowania do usunięcie bucketa

## MFA Delete
- **EXAM** MFA Delete jest często na examie
- Aktywowane w konfigu Object Versioning
- Po aktywacji MFA jest wymagane:
	- Do każdej zmiany stanu Object Versioning
		- Przejścia z enabled na suspended itd
	- Do każdego usunięcia konkretnej wersji obietkversioned-35b23f80-e3c3-4ca9-9519-c1b6867a8eabu `Version Delete`

## Perfomance

### Single Stream Upload
- Domyślna metoda uploadu
- Pozwala na upload danych do 5GB
- Bardzo unreliable, jeżeli stracimy połączenie z internetem w 99% uploadu to musimy zacząć zupełnie od nowa

### Multipart Upload
- Dla plików min. 100MB
- Rozbija plik na mniejsze częsci
	-  max. 10'000 częsci po 5MB
- Sposób szybszy, bardziej reliable

### Accelerated Transfer
- Domyślnie dane podróżujące przez publiczny interned do S3 nie muszą brać najkrótkszej drogi
- Bucket S3 z włączonym Accelerated Trasnfer będzie używak AWS Edge Locations zamiast publicznego internetu i te Edge Locations mają bezpośrednie połączenie ze sobą pozwalając an szybszy transfer

#### Włączanie AT
- Przy tworzeniu bucketu na samym dole jest `Transfer Acceleration`
- Dostajemy wtedy endpoint którego trzeba użyć żeby korzystać z AT


## Encryption
- **EXAM** To nie bukckety S3 są encryptowane, to poszczególne obiekty i dla każdego obiektu możemy wybrać inną formę enkrypcji
- **EXAM** Można ustawić default encryption na poziomie bucketu i wtedy obiekty **które nie mają wybranej enkrypcji** będą miały tę ustawioną

### Client-Side Encryption
- Kiedy enkrypcja następuje już po stonie klienta i na S3 wysyłane są gotowe zakodowane dane
- Użytkownik jest wtedy odpowiedzialny za zakodowanie/rozkodowanie danych i zarządzanie kluczami służącymi do kodowania danych

### Server-Side Encryption
- Dane wysyłane plaintextem ale używając zakodowanego kanału komunikacji
- Są zakodowywane dopiero w moemncie dostarczenia ich do S3
- Są 3 typy SSE:
    - SSE-C : SSE with Customer Provided Keys
    - SSE-S3 : SSE with S3 Managed Keys
    - SSE-KMS : SSE keys stored in KMS

#### SSE-C
- Klient przesyła do S3 dane i klucz, S3 zajmuje się kodowaniem
- S3 przechowuje Hash klucza wraz z plikiem i przy dekodowaniu porównuje najpierw ten hash z hashem klucza podanym do dekodowania
- S3 nie przechowuje klucza, tylko ten hash

#### SSE-S3
- Klient przesyła dane jako plaintext
- S3 generuje `Root Key` który będzie używany do całego procesu enkrypcji
- S3 generuje dodatkowo klucz dla każdego obiektu oddzielnie i używa tego klucza żeby zakodować dane
- Klucz ten jest enkryptowany używając Root Key i jego wersja plaintext jest usuwana
- **EXAM** SSE-S3 używa algorytmu AES-256

##### Wady SSE-S3:
1. Klient nie ma kontroli nad kluczami
2. Klient nie ma kontroli nad rotacją kluczy
3. Brak `role separation`
    - Osoba z uprawnieniami administacyjnymi S3 może dowolnie zakodowywać i odkodowywac obikety
    - Jeżeli przechowujemy na S3 dane wrażliwe to admin S3 raczej nie pownien ich widzieć

### SSE-KMS
- Podobne jak SSE-S3 ale kluczami zarządza KMS
- S3 używa flowu DEK do używania kluczy KMS
- Pozwala na `role separation` na poziomie policy używanych w KMS
- Pozwala na rotację kluczy

### Aktywacja SSE
- Przy przesyłaniu pliku, operacja `PutObject` należy wysłać dodatkowy header `x-amz-server-side-encryption` o wartości:
    - `AES-256` - aktywuje SSE-S3
    - `aws:kms` - aktywuje SSE-KMS
- Przy przesyłaniu pliku przez GUI trzeba znaleźć opcję `Server-side encryption settings`

## S3 Storage Classes

### S3 Standard
- Dane są przechowywane w conajmniej 3 Availibility Zones, dzięki czemu Standard ma 11x9 (99.999999999%) Durability
- Content-MD5 Checksum i CRCs sa używane do zapewnienia spójności danych
- **EXAM** Jezeli uda się dane przechować durable w S3 to w zwrotce dostaniemy HTTP/1.1 200 OK 
- Odpowiedź w milisekundach
    - **EXAM** S3 Standard ma first byte latency = millis
- Obiekty mogą być publiczne

### S3 Standard-IA (Infrequent Access)
- Dane są przechowywane w conajmniej 3 Availibility Zones, dzięki czemu Standard ma 11x9 (99.999999999%) Durability
- Content-MD5 Checksum i CRCs sa używane do zapewnienia spójności danych
- Tańsze przechowywanie, ale płacimy dodatkowo za każdy GB pobierania danych
- Nawet jak przechowujemy dane krócej to i tak płacimy za min. 30dni
- Minimalna opłata za wielkośc pliku to tak jakby plik miał 128kb
- **EXAM** S3 Standard-IA powinno być używane kiedy przechowujemy o długiej dacie ważności, potrzebne dane z których nieczęsto korzystamy
- **EXAM** S3 Standard-IA ma first byte latency = millis

### S3 OneZone-IA 
- Tańsza niż Standard czy Standard-IA
- Tańsze przechowywanie, ale płacimy dodatkowo za każdy GB pobierania danych
- Nawet jak przechowujemy dane krócej to i tak płacimy za min. 30dni
- Minimalna opłata za wielkośc pliku to tak jakby plik miał 128kb
- **EXAM** S3 OneZone-IA dane są przechowywane w **jednej Availibility Zone**
- **EXAM** S3 OneZone-IA powinno być używane kiedy przechowujemy o długiej dacie ważności, ale niekrytyczne i takie które łatwo podmienić
- **EXAM** S3 OneZone-IA ma first byte latency = millis

### S3 Glacier-Instant
- Podobne jak Standard-IA, ale:
    - Droższy retrieval cost
    - Dłuższy minimalny okres przechowywania (90 dni)
- Cały czas mamy instant access do danych
- **EXAM** S3 Glacier-Instant ma first byte latency = millis

### S3 Glacier-Flexible
- Bardzo tanie przechowywanie
- **EXAM** Dane przechowywane w S3 Glacier-Flexible są **cold objects** czyli nie są od ręki gotowe do pobrania i nie mogą być publicznie dostępne!
- Dane z Glaciera są pobierana do S3 Standard-IA **tymczasowo** w czasie (im szybciej tym drożej):
    - Expedited (1-5 min)
    - Standard (3-5 h)
    - Bulk (5-12 h)
- **EXAM** S3 Glacier-Flexible ma first byte latency = minutes or hours
- Służy do przechowywania danych archiwalnych

    
### S3 Glacier Deep Archive
- Najtańsze przechowywanie
- **EXAM** Dane przechowywane w S3 Glacier Deep Archive są **cold objects** czyli nie są od ręki gotowe do pobrania i nie mogą być publicznie dostępne!
- Dane z Glaciera są pobierana do S3 Standard-IA **tymczasowo** w czasie (im szybciej tym drożej):
    - Standard (12h)
    - Bulk (do 48h)
- **EXAM** S3 Glacier Deep Archive ma first byte latency = hours
- Służy do przechowywania danych archiwalnych do których bardzo rzadko musimy mieć dostęp

### S3 Intelligent Tiering
- S3 sam przenosi obiekt między różnymi typami przechowywania w zalezności od tego jak często się go używa
- Tiery:
    - Frequent Access - jak S3 Standard
    po 30 dniach:
    - Infrequent Access - jak S3 Standard-IA
    po 90 dniach:
    - Archive Instant Access - Glacier-Instant
    po 90 do 270 dniach (opcjonalnie):
    - Archive Access - Glacier Flexible
    po 180 do 730 dniach (opcjonalne):
    - Deep Archive - Glacier Deep Archive

