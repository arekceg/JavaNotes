# S3

- Global Storage Platform
- Regional based / resilient
- Public service
	- może być wystawiony na zewnątrz i może być dostępny za pomocą endpointów
- **EXAM** S3 jest **Private by default**
- Nadaje się do przechowywania dużej ilości danych do dystrybucji lub jako miejsce uploadu
- Powinno być używane jako input i output serwisów AWS

## Objects
- Pliki na S3
- **EXAM** Obiekt S3 może mieć od __zera__ bajtów do __5TB__
- `Object key` to jego adres w S3
- Obiekty posiadają:
	- Version ID
	- Metadata
	- Access Control
	- Subresources
- **EXAM** Obiekt ma główne dwie częsci - key i value

## Buckets
- Pojemniki na obiekty
	- Nieskończona ilość obiektów
	- "S3 is an __object__ store - not __file__ nor __block__"
		- nie ma systemu plików, jest płaski
		- nie można go zamontować jako voluminu
	- Wszystkie obiekty są przechowywane __na tym samym poziomie__ - nie ma folderów i podfolderów, są __klucze__
	- UI i CLI przedstawi zawartość Bucketa jako foldery i podfoldery ale w rzeczywistości ma płaską strukturę
		- `folder` w języku S3 nazywa się `prefix`
		- jak `tworzymy nowy folder foo` to tak naprawdę tworzymy obiekt o nazwie `foo/`
- Nazwy Bucketów:
	- **EXAM** Nazwa Bucketu S3 musi być globalnie unique
	- **EXAM** Nazwy Bucketów S3 muszą mieć 3-63 znaki, lowercase, bez podłóg
	- **EXAM** Nazwy Bucketów S3 muszą zaczynać się od małej litery lub cyfry
	- **EXAM** Nazwy Bucketów S3 nie mogą byc formatowane jak adresy IP
- **EXAM** Konto ma soft limit do 100 Bucketów S3 i hard limit do 1000 (via support tickets)
- Istnieją w kontekście regionu
	- Dane z Bucketu nie opuszczają regionu chyba że eksplicite to zrobimy
- Aby usunąć bucket najpierw musimy go opróźnić
	- Bukcets -> Wybrać Bucket -> Empty
	- Delete
- Bucket może mieć nałożone `Resource Policy`
	- Bucket może mieć tylko jedno Resource Policy ale może ono mieć wiele statement

## S3 Bucket Policies (Resource Policy, Security)
- Bucket S3 domyślnie tworzony jest prywany, ma do niego dostęp tylko root user konta któro go stworzyło, ale możemy go otworzyć na publiczny dostęp
- Przy tworzeniu bucketu S3 mamy opcję `Block all public access` - zaznaczenie jej __blokuje__ możliwość udostępnienia bucketu publicznie. Jak odhaczymy tę opcję to bucket nie staje się od razu publiczny ale otwiera się możliwość ustawienia go jako publicznego

### Block all public access
- Mają znaczenie tylko kiedy Anonymous Principal próbuje uzyskać dostęp do bucketu S3

## ACL Access Control List
- Pozwala na zabezpieczanie Objektów lub Bucketów
- ACL to Subresource Objektów lub Bucketów
- Legacy feature, AWS zaleca używanie IAM Policy lub Resource Policy zamiast nich
- O wiele mniej flexible niż Policy

## Static Website Hosting
- Pozwala na dostęp do S3 via HTTP
- Musimy zdefiniować:
	- `Index document`
		- Strona wejściowa naszej strony
		- Domyślna strona na której ląduje konsument
	- `Error document`
		- Dokument który jest wyświetlony w momencie wystapienia błędu
- Po włączeniu tego AWS tworzy dla bucketu Website Endpoint którego można użyć żeby uzyskać dostęp do strony
	- Ten endpoint jest dziwny i wielki, ale możemy użyć R53 żeby stworzyć customową domenę
	- Żeby R53 mógł stworzyć taką domenę to **nazwa bucketu musi być taka sama jak domena**
		- np. domena `foo.bar.org` musi mie bucket `xxx.foo.bar.org` 

Use case:
1.	Offloading
	- Trzymanie statycznych części dynamicznej strony na S3
	- Np. obrazki, statyczne elementy
2.	Out-of-band pages
	- Strony które powinny być dostępne w nieczęstych, nienormalnych sytuacjach
	- np. hostujemy strone na EC2, EC2 pada ale na S3 mamy statyczną stronę na którą możemy przekierować traffic

Włączenie:
1.	S3 -> stworzyć Bucket
2.	Properties -> na sam dół -> Static Website Hosting
	- Na razie będziemy dostawać 403 bo bucket jest niedostepny publicznie
3.	Permissions -> Stworzyć opowiedni BucketPolicy
4.	Żeby mieć elegancki adres trzeba jeszcze skonfigurować Routing w Route53

## Bucket Versioning
-   **EXAM** Bucket Versioning często jest na egzaminie
-   **EXAM** Raz włączonego Bucket Versioning nie można już wyłączyć!!
- **EXAM** Object Versionig można przestawić w `SUSpended`
- **EXAM** Suspended mozna przestawić ponownie w `Enabled`

- Każdy obiekt w S3 oprócz klucza ma też unikanle `ID`
	- `ID` jest nullem jeżeli OV jest wyłączony
- Po włączeniu OV każdy obiekt dostaje swoje ID

### Zmiany w obiekcie
- Jeżeli zmienimy coś w danym obiekcie to poprzednia wersja obiektu dalej isniteje, nie nadpisujemy jej, pojawia się nowy obiekt o tym samym kluczu ale innym ID

### Usuwanie obiektu
- Jeżeli usuwamy obiekt bez podania `Version ID` obiektu obiekt nie zostaje tak naprawdę usunięty
	- Tworzy się tylko `Delete Marker` który przykrywa ten obiekt i sprawia że wygląda jakby został usunięty
	- Jeżeli pozbędziemy sie tego `Delete Marker` to obiekt i wszystkie jego wersje są ponownie widoczne
- Jezeli usuwamy konkretną wersję obiektu (`Version Delete`) to ta wersja usuwana jest naprawdę i nie ma już do niej dostępu

### Koszty
- Każda wersja obiektu na S3 zajmuje miejsce i płacimy za to miejsce
- Nie da sie wyłączyć wersjonowania, można je jedynie zatrzymać tymczasowo
- Jedyny sposób na usunięcie wersjonowania do usunięcie bucketa

## MFA Delete
- **EXAM** MFA Delete jest często na examie
- Aktywowane w konfigu Object Versioning
- Po aktywacji MFA jest wymagane:
	- Do każdej zmiany stanu Object Versioning
		- Przejścia z enabled na suspended itd
	- Do każdego usunięcia konkretnej wersji obietkversioned-35b23f80-e3c3-4ca9-9519-c1b6867a8eabu `Version Delete`

## Perfomance

### Single Stream Upload
- Domyślna metoda uploadu
- Pozwala na upload danych do 5GB
- Bardzo unreliable, jeżeli stracimy połączenie z internetem w 99% uploadu to musimy zacząć zupełnie od nowa

### Multipart Upload
- Dla plików min. 100MB
- Rozbija plik na mniejsze częsci
	-  max. 10'000 częsci po 5MB
- Sposób szybszy, bardziej reliable

### Accelerated Transfer
- Domyślnie dane podróżujące przez publiczny interned do S3 nie muszą brać najkrótkszej drogi
- Bucket S3 z włączonym Accelerated Trasnfer będzie używak AWS Edge Locations zamiast publicznego internetu i te Edge Locations mają bezpośrednie połączenie ze sobą pozwalając an szybszy transfer

#### Włączanie AT
- Przy tworzeniu bucketu na samym dole jest `Transfer Acceleration`
- Dostajemy wtedy endpoint którego trzeba użyć żeby korzystać z AT


## Encryption
- **EXAM** To nie bukckety S3 są encryptowane, to poszczególne obiekty i dla każdego obiektu możemy wybrać inną formę enkrypcji
- **EXAM** Można ustawić default encryption na poziomie bucketu i wtedy obiekty **które nie mają wybranej enkrypcji** będą miały tę ustawioną

### Client-Side Encryption
- Kiedy enkrypcja następuje już po stonie klienta i na S3 wysyłane są gotowe zakodowane dane
- Użytkownik jest wtedy odpowiedzialny za zakodowanie/rozkodowanie danych i zarządzanie kluczami służącymi do kodowania danych

### Server-Side Encryption
- Dane wysyłane plaintextem ale używając zakodowanego kanału komunikacji
- Są zakodowywane dopiero w moemncie dostarczenia ich do S3
- Są 3 typy SSE:
    - SSE-C : SSE with Customer Provided Keys
    - SSE-S3 : SSE with S3 Managed Keys
    - SSE-KMS : SSE keys stored in KMS

#### SSE-C
- Klient przesyła do S3 dane i klucz, S3 zajmuje się kodowaniem
- S3 przechowuje Hash klucza wraz z plikiem i przy dekodowaniu porównuje najpierw ten hash z hashem klucza podanym do dekodowania
- S3 nie przechowuje klucza, tylko ten hash

#### SSE-S3
- Klient przesyła dane jako plaintext
- S3 generuje `Root Key` który będzie używany do całego procesu enkrypcji
- S3 generuje dodatkowo klucz dla każdego obiektu oddzielnie i używa tego klucza żeby zakodować dane
- Klucz ten jest enkryptowany używając Root Key i jego wersja plaintext jest usuwana
- **EXAM** SSE-S3 używa algorytmu AES-256

##### Wady SSE-S3:
1. Klient nie ma kontroli nad kluczami
2. Klient nie ma kontroli nad rotacją kluczy
3. Brak `role separation`
    - Osoba z uprawnieniami administacyjnymi S3 może dowolnie zakodowywać i odkodowywac obikety
    - Jeżeli przechowujemy na S3 dane wrażliwe to admin S3 raczej nie pownien ich widzieć

### SSE-KMS
- Podobne jak SSE-S3 ale kluczami zarządza KMS
- S3 używa flowu DEK do używania kluczy KMS
- Pozwala na `role separation` na poziomie policy używanych w KMS
- Pozwala na rotację kluczy

### Aktywacja SSE
- Przy przesyłaniu pliku, operacja `PutObject` należy wysłać dodatkowy header `x-amz-server-side-encryption` o wartości:
    - `AES-256` - aktywuje SSE-S3
    - `aws:kms` - aktywuje SSE-KMS
- Przy przesyłaniu pliku przez GUI trzeba znaleźć opcję `Server-side encryption settings`

## S3 Storage Classes

### S3 Standard
- Dane są przechowywane w conajmniej 3 Availibility Zones, dzięki czemu Standard ma 11x9 (99.999999999%) Durability
- Content-MD5 Checksum i CRCs sa używane do zapewnienia spójności danych
- **EXAM** Jezeli uda się dane przechować durable w S3 to w zwrotce dostaniemy HTTP/1.1 200 OK 
- Odpowiedź w milisekundach
    - **EXAM** S3 Standard ma first byte latency = millis
- Obiekty mogą być publiczne

### S3 Standard-IA (Infrequent Access)
- Dane są przechowywane w conajmniej 3 Availibility Zones, dzięki czemu Standard ma 11x9 (99.999999999%) Durability
- Content-MD5 Checksum i CRCs sa używane do zapewnienia spójności danych
- Tańsze przechowywanie, ale płacimy dodatkowo za każdy GB pobierania danych
- Nawet jak przechowujemy dane krócej to i tak płacimy za min. 30dni
- Minimalna opłata za wielkośc pliku to tak jakby plik miał 128kb
- **EXAM** S3 Standard-IA powinno być używane kiedy przechowujemy o długiej dacie ważności, potrzebne dane z których nieczęsto korzystamy
- **EXAM** S3 Standard-IA ma first byte latency = millis

### S3 Intelligent Tiering
- S3 sam przenosi obiekt między różnymi typami przechowywania w zalezności od tego jak często się go używa
- Tiery:
    - Frequent Access - jak S3 Standard
    po 30 dniach:
    - Infrequent Access - jak S3 Standard-IA
    po 90 dniach:
    - Archive Instant Access - Glacier-Instant
    po 90 do 270 dniach (opcjonalnie):
    - Archive Access - Glacier Flexible
    po 180 do 730 dniach (opcjonalne):
    - Deep Archive - Glacier Deep Archive

### S3 OneZone-IA 
- Tańsza niż Standard czy Standard-IA
- Tańsze przechowywanie, ale płacimy dodatkowo za każdy GB pobierania danych
- Nawet jak przechowujemy dane krócej to i tak płacimy za min. 30dni
- Minimalna opłata za wielkośc pliku to tak jakby plik miał 128kb
- **EXAM** S3 OneZone-IA dane są przechowywane w **jednej Availibility Zone**
- **EXAM** S3 OneZone-IA powinno być używane kiedy przechowujemy o długiej dacie ważności, ale niekrytyczne i takie które łatwo podmienić
- **EXAM** S3 OneZone-IA ma first byte latency = millis

### S3 Glacier-Instant
- Podobne jak Standard-IA, ale:
    - Droższy retrieval cost
    - Dłuższy minimalny okres przechowywania (90 dni)
- Cały czas mamy instant access do danych
- **EXAM** S3 Glacier-Instant ma first byte latency = millis

### S3 Glacier-Flexible
- Bardzo tanie przechowywanie
- **EXAM** Dane przechowywane w S3 Glacier-Flexible są **cold objects** czyli nie są od ręki gotowe do pobrania i nie mogą być publicznie dostępne!
- Dane z Glaciera są pobierana do S3 Standard-IA **tymczasowo** w czasie (im szybciej tym drożej):
    - Expedited (1-5 min)
    - Standard (3-5 h)
    - Bulk (5-12 h)
- **EXAM** S3 Glacier-Flexible ma first byte latency = minutes or hours
- Służy do przechowywania danych archiwalnych

    
### S3 Glacier Deep Archive
- Najtańsze przechowywanie
- **EXAM** Dane przechowywane w S3 Glacier Deep Archive są **cold objects** czyli nie są od ręki gotowe do pobrania i nie mogą być publicznie dostępne!
- Dane z Glaciera są pobierana do S3 Standard-IA **tymczasowo** w czasie (im szybciej tym drożej):
    - Standard (12h)
    - Bulk (do 48h)
- **EXAM** S3 Glacier Deep Archive ma first byte latency = hours
- Służy do przechowywania danych archiwalnych do których bardzo rzadko musimy mieć dostęp

## S3 Lifecycle
- **EXAM** S3 Lifecycle konfiguruje się jako zasadę lub grupę zasad które dotyczą Bucketu lub grupy obiektów. Zasady składają się z akcji. Pozwalają na automatyczne zarządzanie Storage Class obiektu lub usuwanie go po jakimś casie od uploadu.
- **EXAM** S3 Lifecycle nie potrafi zarządzać obiektami w zależności od tego kiedy ostatni raz były użyte. Do tego służy S3 Intelligent Tiering
- Typy akcji:
    - Transition Action
        Opisuje przejścia między Storage Classami
    - Expiration Action 
        Usuwa obiekt lub wersję obiektu po jakimś czasie
- Można ustawić tranzycję z danego poziomu Storage Class na każdą niższą
    - Nigdy na wyższą!
- **EXAM** S3 Lifecycle nie może przenieśc obiektu z S3 Standard jeżeli obiekt jest tam < 30dni
- **EXAM** S3 Lifecycle nie może przenieśc obiektu z S3 Standard-IA lub One Zone-IA do Glacierów jeżeli był w IA < 30 dni
- Ustawia się to przez:
    - S3 -> Management -> Lifecycle Rules

## S3 Replication
- **EXAM** S3 Replication pozwala na automatyczne, asynchroniczne kopiowanie obiektów między bucketami S3.
- Ustawia się to przez:
    - S3 -> Management -> Replication Rules

### Typy automatycznej replikacji nowych obiektów
- CRR: Cross Region Replication 
    - Nowy obiekt ma się znaleźć w buckecie w innym regionie
- SRR: Same Region Replication
    - Nowy obiekt ma się znaleźć w buckecie w tym samym regionie

- Oba typy potrafią replikować pliki między kontami
- Replication Configuration wykonuje się na **źródłowym** buckecie
- Oprócz Replication Configuration do replikacji należy też definiować Role którą przyjmie S3 przy replikowaniu
    - Rola musi mieć Trust Policy takie żeby mógł ją przyjąć S3
    - Musi mieć takie Premission Policy żeby czytać obiekty ze źródłowego bucketa i zapisywać na docelowym
- S3 Replication odbywa się po SSL więc jest zakodowana
- **EXAM** Jeżeli replikujemy bucket S3 cross-account to domyślnie docelowe konto nie ufa roli którą zdefiniowaliśmy do replikacji na koncie źródłowym. Żeby to zadziałało trzeba na buckecie docelowym stworzyć Bucket Policy takie któro dopuszcza replikację lub zapis _do_ tego bucketu naszej Roli

### Opcje Replikacji
- All Objects / Subset: 
    - Można replikować albo **wszystkie** obiekty z bucketu albo stworzyć filtr dzięki któremu skopiujemy tylko niektóre
- Storage Class: 
    - Można replikować obiekty na ten sam Storage Class lub na inny. Np. robimy backup na niższy Storage Class
- Ownership
    - Domyślnie zreplikowane dane mają za właściciela konto **źródłowe** co może spowodować że konto na które replikujemy nie będzie miało dostępu do tych danych
- RTC Replication Time Control
    - **EXAM** Dzięki RTC Replication Time Control możemy sie upewnić że S3 Replication przebiegnie w ciągu najbliższych 15 minut
    - Bez tego replikacja jest robiona na zasadanie `best effort`

### WAŻNE DO EGZAMINU
- **EXAM** S3 Replication nie jest retroaktywne - w momencie aktywacji syncuje tylko nowe obiekty a nie te już isteniejące
- **EXAM** S3 Replication wymaga włączonego Bucket Versioning na źródłowym i docelowym buckecie
- **EXAM** S3 Replication jest jednokierunkowy - tylko **od** źródłowego **do** docelowego
- **EXAM** S3 Replication potrafi kopiować pliki niezakodowane, zakodowane SSE-S3, SSE-KMS (KMS wymaga dodatkowej konfiguracji). **Nie potrafi** replikować obiektów zakodowanych używając SCE
- **EXAM** S3 Replication może zreplikować tylko te pliki do których dostęp ma właściciel konta triggerującego replikację
- **EXAM** S3 Replication nie potrafi replikować `system events` czyli np. automatycznego przejścia między Storage Class przez S3 Lifecycle
- **EXAM** S3 Replication nie potrafi replikować obiektów z Glacier lub Glacier Deep Archive
- **EXAM** S3 Replication **domyślnie** nie replikuje usuwania obiektów (tworzenia Delete Markers), ale można to włączyć

### **EXAM** SSR Use Cases
- Zbieranie logów z różnych bucketów do jednego
- Synchronizowanie danych między środowiskami (kiedy każde środowisko ma swoje konto)
- Można zreplikować dane do bucketa w celach np. audytowych kiedy nie chcemy dawać wjazdu do głownego bucketa, a dane nie mogą opuścić naszego regionu

### **EXAM** CSR Use Cases
- Backapy w różnych częściach świata
- Replikacja w różnych regionach pozwala obniżyć latencję pobierania obiektów

## S3 Presigned URLs
- Pozwala na dostęp do obiektu w prywatnym buckecie bez przyjmowania konkretnej roli czy logowania sie do AWS
- Osoba używająca takiego URLa interfejsuje z S3 **jako osoba która wygenerowała URL**
- Działa i dla GET i dla PUT
- Działają przez organiczony czas
- Robi się to przez CLI
    - `aws s3 presign {object-uri} --expires-in {duration in seconds}`
- Lub GUI:
    - S3 -> Object -> Object Actions -> Share with presigned URL

### **EXAM** S3 Presigned URLs wazne do egzaminu
- Można stworzyć presigned URL dla obiektu do którego sie nie ma dostępu
    - wtedy ten URL tez nie będzie miał dostępu do obiektu
- Presigned URL ma uprwanienia identity któro go stworzyło **w momencie** użycia URLa
    - a nie w momencie stworzenia
- Nie warto generować Presigned URLs używając przez przyjęta rolę. Temporary Credentials przydzielone roli expires znacznie przed tym jak URL się wyłączy

## S3 Select, Glacier Select
- Pozwala pobierać fragmenty obiektów zamiast całości
    - dzięki temu pobieramy tylko ten fragment który chcemy i za jego transafer płacimy
- Składania a'la SQL
- Możemy tego używać na obiektach CSV, JSON jak i ich skompresowanych wersjach

## S3 Events
- Wysyłanie notyfikacji przy różnych wydarzeniach w S3:
    - Object Created
    - Object Deleted
    - Object Restored (z glaciera)
    - Replication Events
- Notyfikacje mogą lądować na SNS, SQS albo leciec do Lambdy
    - każdy z takich serwisów potrzebuje Resource Policy taką żeby S3 miało principal access
- Konfiuracja na poziomie bucketa
- Stara funkcjonalność trochę, mało eventów, mało serwisów do których mozna wysłać info
    - EventBridge lepszy

## S3 Access Logs
- Logowanie dostępów do jednego bucketa w innym buckecie
- `Best effort` - wrzucenie logów do drugiego bucketa może zająć nawet kilka godzin
- Logi są zarządzane przez `S3 Log Delivery Group` i to ta grupa będzie próbowała zapisać logi w innym buckecie
- Na buckecie docelowym musimy użyć **ACL** żeby ustawić dostęp dla tej grupy

## S3 Object Lock
- Do włączenia dla **nowych** bucketów
    - Włączenie na istniejących wymaga support tiketa
- **WYMAGA OBJECT VERSIONINGU**
- WORM (Write Once Read Many) 
    - Po zapisie wersji obiektu nie można jej modyfikować ani usuwać

### Retention Methods
- Retention Period
- Legal Hold

- Retention period i Legal hold mogą być jednocześnie nałożone na obiekt lub jego wersję
- Bucket może miec ustawiony default retention method

#### Retention Period
- Okres przez który Object Lock utrzymuje sie na obiekcie
- Tryby nakładnia:
    - `COMPLIENCE` - **nie można zmienić ani usunąć object locka przez cały okres retencji!!**
    - `GOVERNANE` - można dać uprawnienia które dopuszczają modyfikację retencji

#### Legal Hold
-  Po nałożeniu Object Lock działa na obiekt aż Legal Hold nie zostanie zdjęty


